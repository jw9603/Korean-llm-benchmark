#!/usr/bin/env python3
"""
LLM Evaluation - Streamlit Web UI

í•œêµ­ì–´ ë²¤ì¹˜ë§ˆí¬ í‰ê°€ ì›¹ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
HuggingFace ëª¨ë¸ì„ ì…ë ¥í•˜ê³ , ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ì„ ì„ íƒí•˜ì—¬ í‰ê°€ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    cd llm_evaluation/webapp
    streamlit run app.py
"""
import json
import subprocess
import sys
from pathlib import Path

import streamlit as st
import pandas as pd

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


def get_available_datasets() -> list[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤. (vLLM ì˜ì¡´ì„± ì—†ì´)"""
    configs_dir = Path(__file__).resolve().parent.parent / "datasets" / "configs"
    return sorted([
        f.stem for f in configs_dir.glob("*.yaml")
        if f.is_file()
    ])

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="LLM Evaluation",
    page_icon="ğŸ¯",
    layout="wide",
)

# ìƒìˆ˜ ì •ì˜
BASE_DIR = Path(__file__).resolve().parent.parent.parent  # default-package
RESULTS_DIR = Path(__file__).resolve().parent.parent / "results"

# ë°ì´í„°ì…‹ ê·¸ë£¹ ì •ì˜
DATASET_GROUPS = {
    "HRM8K": ["hrm8k", "hrm8k_mmmlu"],
    "Ko-MuSR": ["ko_musr_mm", "ko_musr_op", "ko_musr_ta"],
}

# ë°ì´í„°ì…‹ ì„¤ëª…
DATASET_DESCRIPTIONS = {
    "click": "í•œêµ­ ë¬¸í™” ì§€ì‹",
    "csatqa": "ìˆ˜ëŠ¥ ë¬¸ì œ (ëŒ€í•™ìˆ˜í•™ëŠ¥ë ¥ì‹œí—˜)",
    "haerae": "í•œêµ­ ë¬¸í™”/ì‚¬íšŒ ìƒì‹",
    "kmmlu": "í•œêµ­ì–´ MMLU (45ê°œ ë¶„ì•¼)",
    "kmmlu_pro": "KMMLU ê³ ê¸‰ ë²„ì „",
    "kobalt": "í•œêµ­ì–´ ì´í•´ë ¥ í…ŒìŠ¤íŠ¸",
    "hrm8k": "í•œêµ­ì–´ ìˆ˜í•™ ë¬¸ì œ",
    "hrm8k_mmmlu": "ë²ˆì—­ëœ MMMLU ìˆ˜í•™ ë¬¸ì œ",
    "ko_musr_mm": "Ko-MuSR Murder Mysteries",
    "ko_musr_op": "Ko-MuSR Object Placements",
    "ko_musr_ta": "Ko-MuSR Team Allocation",
}


def load_existing_results() -> dict:
    """
    ê¸°ì¡´ í‰ê°€ ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

    Returns:
        dict: {model_id: {dataset: score, ...}, ...}
    """
    results = {}

    if not RESULTS_DIR.exists():
        return results

    for model_dir in RESULTS_DIR.iterdir():
        if not model_dir.is_dir():
            continue

        results_file = model_dir / "results.json"
        if not results_file.exists():
            continue

        try:
            with open(results_file, "r", encoding="utf-8") as f:
                data = json.load(f)

            model_id = model_dir.name
            results[model_id] = {}

            for ds_name, ds_data in data.items():
                if isinstance(ds_data, dict) and "score" in ds_data:
                    results[model_id][ds_name] = ds_data["score"]
        except (json.JSONDecodeError, IOError):
            continue

    return results


def create_leaderboard_df(results: dict, dataset: str = None) -> pd.DataFrame:
    """
    ë¦¬ë”ë³´ë“œ ë°ì´í„°í”„ë ˆì„ ìƒì„±

    Args:
        results: í‰ê°€ ê²°ê³¼
        dataset: íŠ¹ì • ë°ì´í„°ì…‹ë§Œ í‘œì‹œ (Noneì´ë©´ ì „ì²´ í‰ê· )

    Returns:
        pd.DataFrame: ë¦¬ë”ë³´ë“œ ë°ì´í„°í”„ë ˆì„
    """
    if not results:
        return pd.DataFrame()

    rows = []

    for model_id, model_results in results.items():
        if dataset:
            # íŠ¹ì • ë°ì´í„°ì…‹ì˜ ì ìˆ˜
            if dataset in DATASET_GROUPS:
                # ê·¸ë£¹ í‰ê· 
                group_scores = []
                for member in DATASET_GROUPS[dataset]:
                    if member in model_results:
                        group_scores.append(model_results[member])
                if group_scores:
                    score = sum(group_scores) / len(group_scores)
                    rows.append({"ëª¨ë¸": model_id, "ì ìˆ˜": score})
            elif dataset in model_results:
                rows.append({"ëª¨ë¸": model_id, "ì ìˆ˜": model_results[dataset]})
        else:
            # ì „ì²´ í‰ê· 
            scores = list(model_results.values())
            if scores:
                avg = sum(scores) / len(scores)
                rows.append({"ëª¨ë¸": model_id, "í‰ê·  ì ìˆ˜": avg})

    if not rows:
        return pd.DataFrame()

    df = pd.DataFrame(rows)
    score_col = "ì ìˆ˜" if dataset else "í‰ê·  ì ìˆ˜"
    df = df.sort_values(score_col, ascending=False).reset_index(drop=True)
    df.index = df.index + 1  # 1ë¶€í„° ì‹œì‘

    return df


def run_evaluation(model_name: str, datasets: list, gpu_settings: dict):
    """
    í‰ê°€ ì‹¤í–‰ (subprocessë¡œ ì‹¤í–‰)

    Args:
        model_name: HuggingFace ëª¨ë¸ ì´ë¦„
        datasets: í‰ê°€í•  ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸
        gpu_settings: GPU ì„¤ì •

    Returns:
        subprocess.Popen: ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤
    """
    cmd = [
        sys.executable, "-m", "llm_evaluation.main",
        "--model", model_name,
        "--datasets", *datasets,
        "--tensor-parallel-size", str(gpu_settings.get("tp", 1)),
        "--gpu-memory-utilization", str(gpu_settings.get("memory", 0.9)),
    ]

    if gpu_settings.get("max_model_len"):
        cmd.extend(["--max-model-len", str(gpu_settings["max_model_len"])])

    return subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
        cwd=str(BASE_DIR),
    )


def main():
    st.title("ğŸ¯ LLM í‰ê°€ ì‹œìŠ¤í…œ")
    st.markdown("HuggingFace ëª¨ë¸ì„ í•œêµ­ì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€í•©ë‹ˆë‹¤.")

    # ì‚¬ì´ë“œë°”: ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # GPU ì„¤ì •
        st.subheader("GPU ì„¤ì •")
        tensor_parallel = st.number_input(
            "Tensor Parallel Size",
            min_value=1,
            max_value=8,
            value=1,
            help="ì‚¬ìš©í•  GPU ê°œìˆ˜"
        )
        gpu_memory = st.slider(
            "GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ",
            min_value=0.5,
            max_value=1.0,
            value=0.9,
            step=0.05,
        )
        max_model_len = st.number_input(
            "Max Model Length (0=ìë™)",
            min_value=0,
            max_value=131072,
            value=0,
            help="KV cache ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì¤„ì—¬ì„œ ì‚¬ìš© (ì˜ˆ: 16384)"
        )

        st.divider()

        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ì •ë³´
        st.subheader("ê²°ê³¼ ì €ì¥ ìœ„ì¹˜")
        st.code(str(RESULTS_DIR))

    # íƒ­ êµ¬ì„±
    tab1, tab2 = st.tabs(["ğŸš€ í‰ê°€ ì‹¤í–‰", "ğŸ† ë¦¬ë”ë³´ë“œ"])

    # í‰ê°€ ì‹¤í–‰ íƒ­
    with tab1:
        st.header("ëª¨ë¸ í‰ê°€")

        # ëª¨ë¸ ì…ë ¥
        model_name = st.text_input(
            "HuggingFace ëª¨ë¸ ì´ë¦„",
            placeholder="ì˜ˆ: meta-llama/Llama-3.1-8B-Instruct",
            help="HuggingFace Hubì˜ ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ"
        )

        # ë°ì´í„°ì…‹ ì„ íƒ
        st.subheader("ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ ì„ íƒ")

        available_datasets = get_available_datasets()

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if "selected_datasets" not in st.session_state:
            st.session_state.selected_datasets = set()

        # ì „ì²´ ì„ íƒ/í•´ì œ ë²„íŠ¼
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ì „ì²´ ì„ íƒ"):
                st.session_state.selected_datasets = set(available_datasets)
                st.rerun()
        with col2:
            if st.button("ì „ì²´ í•´ì œ"):
                st.session_state.selected_datasets = set()
                st.rerun()

        # ê·¸ë£¹ë³„ë¡œ í‘œì‹œ
        grouped_datasets = set()
        for members in DATASET_GROUPS.values():
            grouped_datasets.update(members)

        general_datasets = [ds for ds in available_datasets if ds not in grouped_datasets]

        cols = st.columns(3)

        with cols[0]:
            st.markdown("**ì¼ë°˜ ë²¤ì¹˜ë§ˆí¬**")
            for ds in general_datasets:
                desc = DATASET_DESCRIPTIONS.get(ds, ds)
                checked = ds in st.session_state.selected_datasets
                if st.checkbox(f"{ds}", value=checked, key=f"cb_{ds}", help=desc):
                    st.session_state.selected_datasets.add(ds)
                elif ds in st.session_state.selected_datasets:
                    st.session_state.selected_datasets.discard(ds)

        with cols[1]:
            st.markdown("**HRM8K (í•œêµ­ì–´ ìˆ˜í•™)**")
            for ds in DATASET_GROUPS.get("HRM8K", []):
                if ds in available_datasets:
                    desc = DATASET_DESCRIPTIONS.get(ds, ds)
                    checked = ds in st.session_state.selected_datasets
                    if st.checkbox(f"{ds}", value=checked, key=f"cb_{ds}", help=desc):
                        st.session_state.selected_datasets.add(ds)
                    elif ds in st.session_state.selected_datasets:
                        st.session_state.selected_datasets.discard(ds)

        with cols[2]:
            st.markdown("**Ko-MuSR (ë‹¤ë‹¨ê³„ ì¶”ë¡ )**")
            for ds in DATASET_GROUPS.get("Ko-MuSR", []):
                if ds in available_datasets:
                    desc = DATASET_DESCRIPTIONS.get(ds, ds)
                    checked = ds in st.session_state.selected_datasets
                    if st.checkbox(f"{ds}", value=checked, key=f"cb_{ds}", help=desc):
                        st.session_state.selected_datasets.add(ds)
                    elif ds in st.session_state.selected_datasets:
                        st.session_state.selected_datasets.discard(ds)

        st.divider()

        # ì„ íƒëœ ë°ì´í„°ì…‹ í‘œì‹œ
        selected_list = list(st.session_state.selected_datasets)
        if selected_list:
            st.info(f"ì„ íƒëœ ë°ì´í„°ì…‹: {', '.join(sorted(selected_list))}")

        # í‰ê°€ ì‹¤í–‰ ë²„íŠ¼
        if st.button("ğŸš€ í‰ê°€ ì‹œì‘", type="primary", use_container_width=True):
            if not model_name:
                st.error("ëª¨ë¸ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            elif not selected_list:
                st.error("ìµœì†Œ í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            else:
                gpu_settings = {
                    "tp": tensor_parallel,
                    "memory": gpu_memory,
                    "max_model_len": max_model_len if max_model_len > 0 else None,
                }

                # ì‹¤í–‰ ì •ë³´ í‘œì‹œ
                st.info(f"**ëª¨ë¸**: {model_name}")

                # subprocessë¡œ ì‹¤í–‰
                with st.spinner("í‰ê°€ ì‹¤í–‰ ì¤‘... (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                    process = run_evaluation(
                        model_name,
                        selected_list,
                        gpu_settings
                    )

                    # ì¶œë ¥ í‘œì‹œ
                    output_container = st.empty()
                    output_text = ""

                    for line in iter(process.stdout.readline, ""):
                        output_text += line
                        output_container.code(output_text[-10000:], language="text")  # ë§ˆì§€ë§‰ 10000ìë§Œ í‘œì‹œ

                    process.wait()

                    if process.returncode == 0:
                        st.success("í‰ê°€ ì™„ë£Œ!")
                        st.balloons()
                    else:
                        st.error(f"í‰ê°€ ì‹¤íŒ¨ (exit code: {process.returncode})")

    # ë¦¬ë”ë³´ë“œ íƒ­
    with tab2:
        st.header("ë¦¬ë”ë³´ë“œ")

        # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        if st.button("ğŸ”„ ê²°ê³¼ ìƒˆë¡œê³ ì¹¨", key="refresh_leaderboard"):
            st.rerun()

        # ê²°ê³¼ ë¡œë“œ
        results = load_existing_results()

        if not results:
            st.warning("ì•„ì§ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í‰ê°€í•´ì£¼ì„¸ìš”.")
        else:
            # ì „ì²´ ê²°ê³¼ í…Œì´ë¸”
            st.subheader("ğŸ“Š ì „ì²´ ê²°ê³¼")

            # í‘œì‹œí•  ë°ì´í„°ì…‹ (ê·¸ë£¹ í¬í•¨)
            grouped_datasets = set()
            for members in DATASET_GROUPS.values():
                grouped_datasets.update(members)

            individual_datasets = [
                ds for ds in get_available_datasets()
                if ds not in grouped_datasets
            ]

            # ë°ì´í„°í”„ë ˆì„ ìƒì„±
            rows = []
            for model_id, model_results in results.items():
                row = {"ëª¨ë¸": model_id}

                # ê°œë³„ ë°ì´í„°ì…‹
                for ds in individual_datasets:
                    row[ds] = model_results.get(ds)

                # HRM8K ê·¸ë£¹ í‰ê· 
                hrm_scores = [model_results.get(m) for m in DATASET_GROUPS["HRM8K"] if model_results.get(m)]
                row["HRM8K"] = sum(hrm_scores) / len(hrm_scores) if hrm_scores else None

                # Ko-MuSR ê·¸ë£¹ í‰ê· 
                musr_scores = [model_results.get(m) for m in DATASET_GROUPS["Ko-MuSR"] if model_results.get(m)]
                row["Ko-MuSR"] = sum(musr_scores) / len(musr_scores) if musr_scores else None

                # ì „ì²´ í‰ê· 
                all_scores = [v for v in row.values() if isinstance(v, (int, float))]
                row["í‰ê· "] = sum(all_scores) / len(all_scores) if all_scores else None

                rows.append(row)

            df = pd.DataFrame(rows)

            # í‰ê·  ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            df = df.sort_values("í‰ê· ", ascending=False).reset_index(drop=True)
            df.index = df.index + 1  # ìˆœìœ„ 1ë¶€í„°

            # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
            cols = ["ëª¨ë¸"] + individual_datasets + ["HRM8K", "Ko-MuSR", "í‰ê· "]
            df = df[[c for c in cols if c in df.columns]]

            # ìŠ¤íƒ€ì¼ ì ìš©
            def highlight_best(s):
                if s.dtype == 'float64':
                    is_max = s == s.max()
                    return ['background-color: #2e7d32; color: white' if v else '' for v in is_max]
                return ['' for _ in s]

            styled_df = df.style.format(
                {col: "{:.4f}" for col in df.columns if col != "ëª¨ë¸"},
                na_rep="-"
            ).apply(highlight_best)

            st.dataframe(styled_df, use_container_width=True, height=400)

            st.divider()

            # ë°ì´í„°ì…‹ë³„ ìƒì„¸ ë³´ê¸°
            st.subheader("ğŸ“ˆ ë°ì´í„°ì…‹ë³„ ìˆœìœ„")

            all_views = individual_datasets + ["HRM8K", "Ko-MuSR"]
            selected_dataset = st.selectbox("ë°ì´í„°ì…‹ ì„ íƒ", all_views)

            if selected_dataset:
                ds_df = create_leaderboard_df(results, selected_dataset)
                if not ds_df.empty:
                    st.dataframe(ds_df, use_container_width=True)


if __name__ == "__main__":
    main()